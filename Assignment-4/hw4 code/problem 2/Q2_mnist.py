# -*- coding: utf-8 -*-
"""mnist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Uxa3AMaQM1AeSAkSA251sVBncURMMKrb
"""

# importing libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import pickle

# importing data set
from google.colab import files
uploaded = files.upload()

# dataset of face images
train_set = pickle.load(open('mnist_small.pkl', 'rb'))

# np.shape(train_set['X']) # (10000, 784) -> 10000 images; each image 28*28

N = np.shape(train_set['X'])[0]
D = np.shape(train_set['X'])[1]
X = np.matrix(train_set['X'])
y = np.matrix(train_set['Y']) # labels -> 0-9

# obtain 2-d embedding (use sklearn)

# approach 1 (PCA) 
from sklearn.decomposition import PCA
model_PCA = PCA(n_components=2)
X = np.matrix(train_set['X'])
X = model_PCA.fit_transform(X)

# K-means clustering with K=10 on 2-d embedding (use sklearn)
# use 10 different initializations
from sklearn.cluster import KMeans

for i in range(10):
  model_KMeans = KMeans(n_clusters=10)
  y_kmeans = model_KMeans.fit_predict(X)

  # Visualising the clusters
  plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], c = 'red', label = '0')
  plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], c = 'blue', label = '1')
  plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], c = 'green', label = '2')
  plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], c = 'yellow', label = '3')
  plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], c = 'black', label = '4')
  plt.scatter(X[y_kmeans == 5, 0], X[y_kmeans == 5, 1], c = 'purple', label = '5')
  plt.scatter(X[y_kmeans == 6, 0], X[y_kmeans == 6, 1], c = 'pink', label = '6')
  plt.scatter(X[y_kmeans == 7, 0], X[y_kmeans == 7, 1], c = 'cyan', label = '7')
  plt.scatter(X[y_kmeans == 8, 0], X[y_kmeans == 8, 1], c = 'brown', label = '8')
  plt.scatter(X[y_kmeans == 9, 0], X[y_kmeans == 9, 1], c = 'orange', label = '9')
  
  plt.title('Clusters of digits (PCA)')
  plt.legend()
  plt.show()

# approach 2 (t-SNE)
from sklearn.manifold import TSNE
model_TSNE = TSNE(n_components=2)
X = np.matrix(train_set['X'])
X = model_TSNE.fit_transform(X)

# K-means clustering with K=10 on 2-d embedding (use sklearn)
# use 10 different initializations
from sklearn.cluster import KMeans

for i in range(10):
  model_KMeans = KMeans(n_clusters=10)
  y_kmeans = model_KMeans.fit_predict(X)
  
    # Visualising the clusters
  plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], c = 'red', label = '0')
  plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], c = 'blue', label = '1')
  plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], c = 'green', label = '2')
  plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], c = 'yellow', label = '3')
  plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], c = 'black', label = '4')
  plt.scatter(X[y_kmeans == 5, 0], X[y_kmeans == 5, 1], c = 'purple', label = '5')
  plt.scatter(X[y_kmeans == 6, 0], X[y_kmeans == 6, 1], c = 'pink', label = '6')
  plt.scatter(X[y_kmeans == 7, 0], X[y_kmeans == 7, 1], c = 'cyan', label = '7')
  plt.scatter(X[y_kmeans == 8, 0], X[y_kmeans == 8, 1], c = 'brown', label = '8')
  plt.scatter(X[y_kmeans == 9, 0], X[y_kmeans == 9, 1], c = 'orange', label = '9')

  plt.title('Clusters of digits (t-SNE)')
  plt.legend()
  plt.show()

  
# which is better? (PCA or t-SNE)